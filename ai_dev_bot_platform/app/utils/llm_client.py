import logging
import httpx
import google.generativeai as genai
from app.services.api_key_manager import APIKeyManager

logger = logging.getLogger(__name__)

class LLMClient:
    def __init__(self, api_key_manager: APIKeyManager):
        self.api_key_manager = api_key_manager
        self.google_api_key_configured = False
        google_key = self.api_key_manager.get_next_key("google")
        if google_key:
            try:
                genai.configure(api_key=google_key)
                self.google_api_key_configured = True
                logger.info("Google Gemini API configured.")
            except Exception as e:
                logger.error(f"Failed to configure Google Gemini API: {e}")
        else:
            logger.warning("Google API key not found in APIKeyManager for LLMClient.")

    async def call_gemini(self, prompt: str, model_name: str = "gemini-1.5-flash-latest") -> dict:
        if not self.google_api_key_configured:
            return {
                "text_response": "Error: Google Gemini API not configured.",
                "input_tokens": 0,
                "output_tokens": 0,
                "model_name_used": model_name
            }
        try:
            model = genai.GenerativeModel(model_name)
            response = await model.generate_content_async(prompt)
            if response.parts:
                return {
                    "text_response": response.text,
                    "input_tokens": response.usage_metadata.prompt_token_count if hasattr(response, 'usage_metadata') else 0,
                    "output_tokens": response.usage_metadata.candidates_token_count if hasattr(response, 'usage_metadata') else 0,
                    "model_name_used": model_name
                }
            elif response.prompt_feedback and response.prompt_feedback.block_reason:
                logger.warning(f"Gemini response blocked. Reason: {response.prompt_feedback.block_reason_message}")
                return {
                    "text_response": f"Error: Content generation blocked by safety settings ({response.prompt_feedback.block_reason_message}).",
                    "input_tokens": 0,
                    "output_tokens": 0,
                    "model_name_used": model_name
                }
            return {
                "text_response": "Error: No content generated by Gemini or unknown error.",
                "input_tokens": 0,
                "output_tokens": 0,
                "model_name_used": model_name
            }
        except Exception as e:
            logger.error(f"Error calling Gemini API ({model_name}): {e}", exc_info=True)
            return {
                "text_response": f"Error communicating with Gemini: {str(e)}",
                "input_tokens": 0,
                "output_tokens": 0,
                "model_name_used": model_name
            }

    async def call_openrouter(self, model_name: str, prompt: str, system_prompt: str = None) -> dict:
        openrouter_key = self.api_key_manager.get_next_key("openrouter")
        if not openrouter_key:
            return {
                "text_response": "Error: OpenRouter API key not configured.",
                "input_tokens": 0,
                "output_tokens": 0,
                "model_name_used": model_name
            }

        headers = {
            "Authorization": f"Bearer {openrouter_key}",
            "Content-Type": "application/json"
        }
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        data = {
            "model": model_name,
            "messages": messages
        }
        api_url = "https://openrouter.ai/api/v1/chat/completions"

        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(api_url, headers=headers, json=data)
                response.raise_for_status()
                result = response.json()
                if result.get("choices") and result["choices"][0].get("message"):
                    return {
                        "text_response": result["choices"][0]["message"]["content"],
                        "input_tokens": result.get("usage", {}).get("prompt_tokens", 0),
                        "output_tokens": result.get("usage", {}).get("completion_tokens", 0),
                        "model_name_used": model_name
                    }
                logger.error(f"Unexpected OpenRouter response format: {result}")
                return {
                    "text_response": "Error: Unexpected response format from OpenRouter.",
                    "input_tokens": 0,
                    "output_tokens": 0,
                    "model_name_used": model_name
                }
        except httpx.HTTPStatusError as e:
            logger.error(f"HTTP error calling OpenRouter API ({model_name}): {e.response.status_code} - {e.response.text}", exc_info=True)
            return {
                "text_response": f"Error with OpenRouter API ({e.response.status_code}): {e.response.text}",
                "input_tokens": 0,
                "output_tokens": 0,
                "model_name_used": model_name
            }
        except Exception as e:
            logger.error(f"Error calling OpenRouter API ({model_name}): {e}", exc_info=True)
            return {
                "text_response": f"Error communicating with OpenRouter: {str(e)}",
                "input_tokens": 0,
                "output_tokens": 0,
                "model_name_used": model_name
            }